# Case study Сергеенков М.С.

## Немного о проекте
- С октября 2019 года я работаю в дочке самого крупного банка России ведущим разработчиком.
- В составе небольшой команды занимаюсь разработкой некоторой системы управления.
- Разработка ведется на Ruby, а проекту уже пару лет.
- На проекте перформанс является не самой сильной стороной, поэтому есть несколько долго выполняемых задач над которыми можно было бы поработать.
- Мониторинг запросов существует, у нас используется Elastic APM, но по факту он практически не используется. В планах разобраться с ним, и сделать внутренний мини доклад на тему перформанса и нагрузочного тестирования.

## Оптимизация в реальном бою :)
- Навыки полученные в этом курсе, мне пришлось применять в срочном порядке уже после прохождения второго занятия.
- Как писал выше, у нас есть несколько задач, которые работают с большим объемом данных, их работа занимает от 10 до 90 минут в зависимости от среды (production или qa) и типа данных.
- И вот, в один прекрасный момент пришла команда на доработку одной из задач. Задачу я в общем-то решил быстро. Но когда изменения оказались в мастере, а потом и на production (самое печальное, что именно в этот раз изменения случайно миновали ручное тестирование на qa), выяснилось, пода перезагружается из-за OOM killer'a. И тут осенило, ну конечно же, фактический объем данных в памяти должен был увеличится в несколько раз.
- Изначально на выполнение этой задачи требовалось порядка 45 минут на поде kubernetes c целым процессором и 1.5ГБ памяти. Ресурсы поды были забиты практически полностью (во всяком случае по памяти). А после изменений, скорее всего должно было потребляться больше 10ГБ памяти.
- И тут началось :)
- Бюджетом оказались характеристики поды, а метрикой объем потребляемой памяти.
- Для фидбек-лупа я создал скрипт, который содержал те самые изменения, которые привели к проблеме (фактически это был некоторый индекс данных в виде хеша, который потом использовался при создании объектов). А также скрипты с benchmark, ruby-prof и memory_profiler. Взял ограниченный объем данных. И начал профилировать.
- Первую проблему показал ruby-prof: очень много времени уходило на работу с Array#select, в котором было много обращений к объектам ActiveRecord. После того, как я вынес эти обращения за пределы Array#select, время работы уменьшилось в два раза.
- Вторую проблему показал memory_profiler: после обработки 1/64 данных индекс весит около 1ГБ. А так как мне по факту нужен был размер массива объектов, то я начал использовать метод Array#count и хранить всего лишь цифру. Также в виде ключа я стал использовать id объекта, т.к. потом я мог и по нему обращаться к индексу. Таким образом на выходе я получил хэш очень маленького объема.
- Третью проблему показала интуиция: Ключи-то для индекса хранились в массиве и для того, чтобы по мере добавления новой информации, уже отработанная информация (Объект ActiveRecord из которых мне стал нужен только id) собиралась GC, я заменил итератор Array#each на цикл while c вызовом Array#pop для массива.
- Четвертую проблему показал ruby-prof: Очень много времени тратилось на работу ActiveRecord, создавалось куча рельсов объектов. И я решил формировать массив (по которому я делал Array#count) из хэшей. И это стало победным решением.
- В итоге benchmark показал, что полный объем данных обрабатывается за 15 минут. Т.е. прирост по времени работы задачи составил 15 минут, а вся задача выполняется за 60 минут.
- А memory_profiler показал, что за время работы выделяется 1ГБ памяти, а сам индекс весит чуть меньше одного 1МБ.
- Запуск задачи в поде показал, что память выделяется равномерно. 
- Таким образом ресурсы поды стали и защитой от деградации.

Индекс был типа:

```ruby
{
  Объект ActiveRecord => [Объект ActiveRecord, Объект ActiveRecord, ... ],
  Объект ActiveRecord => [Объект ActiveRecord, Объект ActiveRecord, ... ],
  ...
}
```

Потом стал:

```ruby
{
  Integer => Integer,
  Integer => Integer,
  ...
}
```
